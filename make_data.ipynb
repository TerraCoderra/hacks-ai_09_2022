{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54f78405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import glob\n",
    "import fiona\n",
    "from albumentations import Rotate\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.utils import draw_segmentation_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88d46172",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_train_path = 'content_train/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a65325ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция создает директорию, если ее не существует по указанному пути\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f19e41fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция удаляет пробелы в именах файлов, если такие есть\n",
    "def del_space(train_path):\n",
    "    for file in sorted(os.listdir(train_path)):\n",
    "        if ' ' in file:\n",
    "            os.rename(str(train_path)+file , str(train_path)+file.replace(\" \", \"\"))\n",
    "            print(file + ' переименован в ' + str(train_path)+file.replace(\" \", \"\"))\n",
    "            \n",
    "# функция находит '.png' файлы, для которых нет соответствующих '.geojson' файлов,\n",
    "# и наоборот: находит '.geojson' файлы без соответствующих '.png' файлов\n",
    "def find_waste_files(train_path):\n",
    "    del_list = []\n",
    "    for file in sorted(os.listdir(train_path)):\n",
    "        if file[-3:] == 'png':\n",
    "            if (os.path.exists(str(train_path)+file[:-3]+'geojson'))!=True:\n",
    "                del_list.append(str(train_path)+file[:-3]+'png')\n",
    "        if file[-7:] == 'geojson':\n",
    "            if (os.path.exists(str(train_path)+file[:-7]+'png'))!=True:\n",
    "                del_list.append(str(train_path)+file[:-7]+'geojson')\n",
    "    return del_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a45f72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переименовываем файлы с пробелами\n",
    "del_space(main_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62fd1cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем список фотографий, для которых нет масок, а также - масок без соответствующих фото \n",
    "del_list = find_waste_files(main_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5c9b647e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['content_train/train/113.geojson', 'content_train/train/176.png', 'content_train/train/257.png', 'content_train/train/393.geojson', 'content_train/train/527.geojson', 'content_train/train/647.png', 'content_train/train/688.geojson', 'content_train/train/72.geojson']\n"
     ]
    }
   ],
   "source": [
    "print(del_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eecf4dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл content_train/train/113.geojson удален\n",
      "Файл content_train/train/176.png удален\n",
      "Файл content_train/train/257.png удален\n",
      "Файл content_train/train/393.geojson удален\n",
      "Файл content_train/train/527.geojson удален\n",
      "Файл content_train/train/647.png удален\n",
      "Файл content_train/train/688.geojson удален\n",
      "Файл content_train/train/72.geojson удален\n"
     ]
    }
   ],
   "source": [
    "# удаляем лишние файлы\n",
    "for file in del_list:\n",
    "    os.remove(file)\n",
    "    print(\"Файл \" + file + \" удален\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "85586294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция разрезает изображение с шириной width и высотой height на 8 частей:\n",
    "# по ширине делим на h_parts=4 частей, по высоте - на v_parts=2 части\n",
    "def crop_images(main_path, images_path, parts_path, im_list=[], height=1232, \n",
    "                width=1624, h_parts=4, v_parts=2):\n",
    "    for file in sorted(os.listdir(main_path)):\n",
    "        if file[-3:] == 'png':\n",
    "            path = images_path + file\n",
    "            path2 = parts_path + file[:-4]\n",
    "            image = cv2.imread(str(path), cv2.IMREAD_COLOR)\n",
    "            image = np.array(image)\n",
    "            for i in range(0, v_parts):\n",
    "                for j in range(0, h_parts):\n",
    "                    v_from = int(i*(height/v_parts))\n",
    "                    v_to = int((i+1)*(height/v_parts))\n",
    "                    h_from = int(j*(width/h_parts))\n",
    "                    h_to = int((j+1)*(width/h_parts))\n",
    "                    im1 = image[v_from:v_to, h_from:h_to]\n",
    "                    cv2.imwrite(path2+'_' + str((i*4)+(j+1)) + '.png', im1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84ba68a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определим пути к следующим директориям:\n",
    "# для разрезанных изображений трейна\n",
    "train_parts_images = 'content_train/parts_images/'\n",
    "# для изображений с наложенными масками\n",
    "masks_with_images_path = 'content_train/masks_with_images/'\n",
    "# для масок трейна\n",
    "train_masks_path = 'content_train/masks/'\n",
    "# для разрезанных масок трейна\n",
    "train_parts_masks = 'content_train/parts_masks/'\n",
    "# для изображений после аугментации\n",
    "aug_images = 'content_train/aug_images/'\n",
    "# для масок после аугментации\n",
    "aug_masks = 'content_train/aug_masks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "279cad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим необходимые директории\n",
    "create_dir('content_train/parts_images')\n",
    "create_dir('content_train/masks')\n",
    "create_dir('content_train/parts_masks')\n",
    "create_dir('content_train/masks_with_images')\n",
    "create_dir('content_train/aug_masks')\n",
    "create_dir('content_train/aug_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251a5534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd876c32",
   "metadata": {},
   "source": [
    "## Маски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7059c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вспомогательные функции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4078cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_layout(path: str, image_size: tuple) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Метод для чтения geojson разметки и перевода в numpy маску\n",
    "    \"\"\"\n",
    "    with open(path, 'r', encoding='cp1251') as f:  # some files contain cyrillic letters, thus cp1251\n",
    "        json_contents = json.load(f)\n",
    "\n",
    "    num_channels = 2\n",
    "    mask_channels = [np.zeros(image_size, dtype=np.float32) for _ in range(num_channels)]\n",
    "    mask = np.zeros(image_size, dtype=np.float32)\n",
    "\n",
    "    if type(json_contents) == dict and json_contents['type'] == 'FeatureCollection':\n",
    "        features = json_contents['features']\n",
    "    elif type(json_contents) == list:\n",
    "        features = json_contents\n",
    "    else:\n",
    "        features = [json_contents]\n",
    "\n",
    "    for shape in features:\n",
    "        channel_id = 1\n",
    "        mask = parse_mask(shape['geometry'], image_size)\n",
    "        mask_channels[channel_id] = np.maximum(mask_channels[channel_id], mask)\n",
    "\n",
    "    mask_channels[0] = 1 - np.max(mask_channels[1:], axis=0)\n",
    "\n",
    "    return np.stack(mask_channels, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48a2e10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_polygon(coordinates, image_size): \n",
    "    mask = np.zeros(image_size, dtype=np.float32) \n",
    "    \n",
    "    if len(coordinates) == 1: \n",
    "        points = [np.int32(coordinates)] \n",
    "        cv2.fillPoly(mask, points, 1) \n",
    "    else: \n",
    "        points = [np.int32([coordinates[0]])] \n",
    "        cv2.fillPoly(mask, points, 1) \n",
    "    \n",
    "        for polygon in coordinates[1:]: \n",
    "            points = [np.int32([polygon])] \n",
    "            cv2.fillPoly(mask, points, 0) \n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n",
    "def parse_mask(shape, image_size):\n",
    "    \"\"\"\n",
    "    Метод для парсинга фигур из geojson файла\n",
    "    \"\"\"\n",
    "    mask = np.zeros(image_size, dtype=np.float32)\n",
    "    coordinates = shape['coordinates']\n",
    "    if shape['type'] == 'MultiPolygon':\n",
    "        for polygon in coordinates:\n",
    "            mask += parse_polygon(polygon, image_size)\n",
    "    else:\n",
    "        mask += parse_polygon(coordinates, image_size)\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ae36064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206.geojson (947, 1248, 3)\n"
     ]
    }
   ],
   "source": [
    "# Преобразуем маски в png и сохраним в директории \"content_train/masks\"\n",
    "for file in os.listdir(main_train_path):\n",
    "    if file[-7:] == 'geojson':\n",
    "        # Получаем соответствующий файл разметки\n",
    "        json_path = main_train_path +str(file)\n",
    "        mask = read_layout(json_path, (1232, 1624))\n",
    "        image = cv2.imread(main_train_path + str(file[:-7])+'png', cv2.IMREAD_COLOR)\n",
    "        if image.shape[0] == 1232 and image.shape[1]== 1624:\n",
    "            image = np.array(image / 255, dtype=np.float32)\n",
    "            transform = transforms.Compose([\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "            image = transform(image)\n",
    "            tensor_mask = transform(mask)\n",
    "            image_with_mask = draw_segmentation_masks((image.cpu() * 255).type(torch.uint8),\n",
    "                                                      tensor_mask.type(torch.bool), alpha=0.2)\n",
    "            image_with_mask = np.moveaxis(image_with_mask.cpu().numpy(), 0, -1)\n",
    "            cv2.imwrite(masks_with_images_path + str(file[:-7])+'png', image_with_mask)\n",
    "            mask = 255*mask[:, :,-1]\n",
    "            cv2.imwrite(train_masks_path + str(file[:-7])+'png', mask)\n",
    "        else:\n",
    "            print(file, image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "aa118cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# На основе анализа фотографий с наложенными на них масками, расположенными в директории\n",
    "# 'content_train/masks_with_images/', получаем номера изображений маски для которых\n",
    "# могут быть некорректными\n",
    "del_list = [206,9,14,29,36,38,42,44,46,51,52,63,70,85,91,96,111,114,126,138,155,178,\n",
    "           179,181,188,191,197,198,199,209,211,223,253,262,264,269,272,275,277,279,\n",
    "           280,284,298,347,349,370,374,383,404,410,411,420,440,488,504,530,531,537,\n",
    "           540,542,543,546,559,560,562,569573,579,587,589,591,593,606,607,612,621,\n",
    "           622,638,645,648,653,657,671,673,677,681,685,689,712,715,716,726,728,741,\n",
    "           744,745,771,778]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c05ac554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим лишние файлы из директории, содержащей маски \n",
    "for file in sorted(os.listdir(train_masks_path)):\n",
    "    if int(file[:-4]) in del_list:\n",
    "        os.remove(train_masks_path + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3fefd228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "556"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(train_masks_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0e289e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# разрежем изображения и маски трейна\n",
    "crop_images(train_masks_path, train_masks_path, train_parts_masks)\n",
    "crop_images(train_masks_path, main_train_path, train_parts_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "87eabe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим директории для разрезанных изображении и масок теста\n",
    "create_dir('content/test/parts_images')\n",
    "create_dir('content/test/parts_masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "962bc744",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'content/test/eyes/'\n",
    "test_path_parts = 'content/test/parts_images/'\n",
    "# разрежем изображения теста\n",
    "crop_images(test_path, test_path, test_path_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3e3f5af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4448, 4448)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сравним число изображений и масок трейновых данных\n",
    "len(os.listdir(train_parts_masks)),len(os.listdir(train_parts_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc41636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54e294d8",
   "metadata": {},
   "source": [
    "## Аугментация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b016f8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# формируем списки с изображениями и масками\n",
    "def make_train_test_data(images_path, masks_path):\n",
    "    data_x = []\n",
    "    data_y = []\n",
    "    for file in os.listdir(masks_path):\n",
    "        #print(file[2:-6])\n",
    "        if file in os.listdir(images_path):\n",
    "            data_x.append(images_path + file)\n",
    "            data_y.append(masks_path + file)\n",
    "    return(data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "dd3d8991",
   "metadata": {},
   "outputs": [],
   "source": [
    "(images, masks) = make_train_test_data(train_parts_images,train_parts_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "28826356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для аугментации данных: увеличим число данных за счет \n",
    "# рандомного поворота на предельные 12 градусоа\n",
    "def augment_data(images, masks, save_imgs_path,save_masks_path, augment=True):\n",
    "    #size = (1624, 1232)\n",
    "    for idx, (x, y) in tqdm(enumerate(zip(images,masks)), total=len(images)):\n",
    "        name = x.split('/')[-1].split('.')[0]\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        y = cv2.imread(y, cv2.IMREAD_COLOR)\n",
    "        \n",
    "        if augment == True:\n",
    "            aug = Rotate(limit=12, p=1)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x3 = augmented[\"image\"]\n",
    "            y3 = augmented[\"mask\"]\n",
    "            \n",
    "            X = [x, x3]\n",
    "            Y = [y, y3]\n",
    "        else:\n",
    "            X = [x]\n",
    "            Y = [y]\n",
    "        index = 0\n",
    "        for i, m in zip(X,Y):\n",
    "            tmp_image_name = name + '_' + str(index) + '.png'\n",
    "            tmp_mask_name = name + '_' + str(index) + '.png'\n",
    "            \n",
    "            image_path = str(Path(save_imgs_path, tmp_image_name))\n",
    "            mask_path = str(Path(save_masks_path, tmp_mask_name))\n",
    "            cv2.imwrite(image_path, i)\n",
    "            cv2.imwrite(mask_path, m)\n",
    "            \n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4a2bf2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# После аугментации изображения сохранятся в директории \"content_train/aug_images\",\n",
    "# маски сохранятся в директории \"content_train/aug_masks\"\n",
    "augment_data(images,masks, aug_images, aug_masks, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968c7c37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
